PARAMETER ...
Namespace(batch_size=5, decay_rate=0.0001, epoch=200, gpu='0', learning_rate=0.001, log_dir='deform_contactnet', model='deform_contactnet', num_category=1, num_point=1024, optimizer='Adam', process_data=False, use_cpu=False, use_normals=True, use_uniform_sample=False)
Load dataset ...
23
No existing model, starting training from scratch...
Epoch 1 (1/200):
  0%|                                                                                              | 0/3 [00:00<?, ?it/s]
5 8 8894
target:  tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')
pred:  tensor([[0.4751, 0.4751, 0.4751,  ..., 0.4751, 0.4751, 0.4751],
        [0.4312, 0.4712, 0.5823,  ..., 0.5378, 0.5527, 0.5636],
        [0.5269, 0.4708, 0.5639,  ..., 0.4952, 0.5042, 0.5258],
        [0.4802, 0.4833, 0.3985,  ..., 0.4802, 0.4809, 0.4802],
        [0.4456, 0.4456, 0.4456,  ..., 0.3807, 0.3944, 0.3666]],
       device='cuda:0', grad_fn=<ViewBackward>)
100%|██████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:08<00:00,  2.92s/it]
  0%|                                                                                              | 0/3 [00:00<?, ?it/s]
5 8 8894
target:  tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')
pred:  tensor([[0.3936, 0.3936, 0.4295,  ..., 0.3936, 0.4052, 0.3936],
        [0.6140, 0.6140, 0.4324,  ..., 0.4604, 0.6140, 0.6140],
        [0.4905, 0.4905, 0.4905,  ..., 0.4905, 0.4905, 0.4905],
        [0.3693, 0.2683, 0.3693,  ..., 0.3693, 0.3693, 0.3953],
        [0.4318, 0.3909, 0.4728,  ..., 0.4470, 0.4564, 0.4318]],
       device='cuda:0', grad_fn=<ViewBackward>)
Loss:  tensor(0.6718, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)
5 8 8894
target:  tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')
pred:  tensor([[0.4985, 0.3932, 0.4229,  ..., 0.3897, 0.4985, 0.4985],
        [0.6105, 0.6124, 0.6105,  ..., 0.6469, 0.6313, 0.6269],
        [0.2916, 0.2916, 0.2051,  ..., 0.2916, 0.1679, 0.2916],
        [0.4037, 0.5222, 0.4154,  ..., 0.4037, 0.4037, 0.3652],
        [0.4713, 0.6414, 0.5651,  ..., 0.5689, 0.5731, 0.4713]],
       device='cuda:0', grad_fn=<ViewBackward>)
Loss:  tensor(0.6527, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)
Got 82828.0 / 26682 with accuracy 310.42650475976313
Train Instance Accuracy: nan
  0%|                                                                                              | 0/3 [00:03<?, ?it/s]
Traceback (most recent call last):
  File "train.py", line 261, in <module>
    main(args)
  File "train.py", line 187, in main
    for batch_id, (points, target) in tqdm(enumerate(trainDataLoader, 0), total=len(trainDataLoader), smoothing=0.9):
  File "/home/trannguyenle/anaconda3/envs/rlgpu/lib/python3.7/site-packages/tqdm/std.py", line 1195, in __iter__
    for obj in iterable:
  File "/home/trannguyenle/anaconda3/envs/rlgpu/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 435, in __next__
    data = self._next_data()
  File "/home/trannguyenle/anaconda3/envs/rlgpu/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1068, in _next_data
    idx, data = self._get_data()
  File "/home/trannguyenle/anaconda3/envs/rlgpu/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1034, in _get_data
    success, data = self._try_get_data()
  File "/home/trannguyenle/anaconda3/envs/rlgpu/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 872, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/trannguyenle/anaconda3/envs/rlgpu/lib/python3.7/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/trannguyenle/anaconda3/envs/rlgpu/lib/python3.7/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/trannguyenle/anaconda3/envs/rlgpu/lib/python3.7/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/trannguyenle/anaconda3/envs/rlgpu/lib/python3.7/multiprocessing/connection.py", line 921, in wait
    ready = selector.select(timeout)
  File "/home/trannguyenle/anaconda3/envs/rlgpu/lib/python3.7/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt