PARAMETER ...
Namespace(batch_size=5, decay_rate=0.0001, epoch=200, gpu='0', learning_rate=0.001, log_dir='deform_contactnet', model='deform_contactnet', num_category=1, num_point=1024, optimizer='Adam', process_data=False, use_cpu=False, use_normals=True, use_uniform_sample=False)
Load dataset ...
23
No existing model, starting training from scratch...
Epoch 1 (1/200):
  0%|                                                                                              | 0/3 [00:00<?, ?it/s]
5 8 8894
target:  tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')
pred:  tensor([[0.4435, 0.5235, 0.4501,  ..., 0.4314, 0.4250, 0.4275],
        [0.6582, 0.6582, 0.6582,  ..., 0.6582, 0.6582, 0.6582],
        [0.5256, 0.5256, 0.6327,  ..., 0.6010, 0.6166, 0.6591],
        [0.6055, 0.5722, 0.6271,  ..., 0.5249, 0.5176, 0.5186],
        [0.5107, 0.5107, 0.5107,  ..., 0.5107, 0.5107, 0.5107]],
       device='cuda:0', grad_fn=<ViewBackward>)
Loss:  tensor(0.7503, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)
torch.Size([5, 8894])
Got 15598.0 / 5 with accuracy 311960.0
5 8 8894
target:  tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')
pred:  tensor([[0.5551, 0.5501, 0.5551,  ..., 0.7218, 0.7247, 0.6984],
        [0.5451, 0.4134, 0.5451,  ..., 0.4705, 0.4647, 0.4786],
        [0.4776, 0.4493, 0.4776,  ..., 0.4285, 0.4776, 0.4504],
        [0.3988, 0.3988, 0.3988,  ..., 0.3841, 0.3988, 0.3988],
        [0.5677, 0.5677, 0.7348,  ..., 0.6020, 0.5677, 0.6011]],
       device='cuda:0', grad_fn=<ViewBackward>)
Loss:  tensor(0.7361, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)
torch.Size([5, 8894])
Got 35892.0 / 10 with accuracy 358920.0
5 8 8894
target:  tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')
pred:  tensor([[0.3346, 0.3346, 0.3346,  ..., 0.3346, 0.4863, 0.3346],
        [0.4284, 0.4204, 0.5204,  ..., 0.5886, 0.5758, 0.5790],
        [0.4819, 0.4678, 0.4819,  ..., 0.4819, 0.4819, 0.4445],
        [0.6813, 0.6813, 0.6813,  ..., 0.6813, 0.6813, 0.6584],
        [0.4103, 0.4403, 0.4103,  ..., 0.4103, 0.4211, 0.4358]],
       device='cuda:0', grad_fn=<ViewBackward>)
 67%|█████████████████████████████████████████████████████████▎                            | 2/3 [00:08<00:04,  4.39s/it]
Traceback (most recent call last):
  File "train.py", line 262, in <module>
    main(args)
  File "train.py", line 206, in main
    loss.backward()
  File "/home/trannguyenle/anaconda3/envs/rlgpu/lib/python3.7/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/trannguyenle/anaconda3/envs/rlgpu/lib/python3.7/site-packages/torch/autograd/__init__.py", line 132, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt